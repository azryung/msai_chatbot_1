# import streamlit as st
# import os
# from openai import AzureOpenAI
# from dotenv import load_dotenv

# # 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# # ë¡œì»¬ì—ì„œëŠ” .env íŒŒì¼ì„ ì½ê³ , Streamlit Cloudì—ì„œëŠ” Secretsë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
# load_dotenv()

# st.title("ğŸ¤– ë‚˜ì˜ ì²« AI ì±—ë´‡")

# # [ì•ˆì „ ì¥ì¹˜] í•„ìˆ˜ í‚¤ê°€ ì œëŒ€ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
# if not os.getenv("AZURE_OAI_KEY"):
#     st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì´ë‚˜ Streamlit Secretsë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
#     st.stop()

# # 2. Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# # ì´ì œ ì§ì ‘ ì ì§€ ì•Šê³  os.getenvë¥¼ í†µí•´ ê°€ì ¸ì˜µë‹ˆë‹¤.
# client = AzureOpenAI(
#     api_key=os.getenv("AZURE_OAI_KEY"), 
#     api_version="2025-01-01-preview", 
#     azure_endpoint=os.getenv("AZURE_OAI_ENDPOINT")
# )

# # 3. ëŒ€í™”ê¸°ë¡(Session State) ì´ˆê¸°í™”
# if "messages" not in st.session_state:
#     st.session_state.messages = []

# # 4. í™”ë©´ì— ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶œë ¥
# for message in st.session_state.messages:
#     with st.chat_message(message["role"]):
#         st.markdown(message["content"])

# # 5. ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
# if prompt := st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"):
#     # (1) ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ & ì €ì¥
#     st.chat_message("user").markdown(prompt)
#     st.session_state.messages.append({"role": "user", "content": prompt})

#     # (2) AI ì‘ë‹µ ìƒì„±
#     with st.chat_message("assistant"):
#         try:
#             response = client.chat.completions.create(
#                 # ì¤‘ìš”: ëª¨ë¸ ì´ë¦„ë„ ë³€ìˆ˜ë¡œ ë°›ì•„ì™€ì•¼ ë°°í¬ëª…ì´ ë°”ë€Œì–´ë„ ì½”ë“œë¥¼ ì•ˆ ê³ ì³ë„ ë©ë‹ˆë‹¤.
#                 model=os.getenv("AZURE_OAI_DEPLOYMENT"), 
#                 messages=[
#                     {"role": m["role"], "content": m["content"]}
#                     for m in st.session_state.messages
#                 ]
#             )
#             assistant_reply = response.choices[0].message.content
#             st.markdown(assistant_reply)

#             # (3) AI ì‘ë‹µ ì €ì¥
#             st.session_state.messages.append({"role": "assistant", "content": assistant_reply})
            
#         except Exception as e:
#             # ì—ëŸ¬ê°€ ë‚˜ë©´ ë¶‰ì€ìƒ‰ ë°•ìŠ¤ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
#             st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


import streamlit as st
import os
from openai import AzureOpenAI
from dotenv import load_dotenv

# ì™€ì¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì´ íŒŒì¼ì€ ê·¸ëŒ€ë¡œ ë‘ì‹œë©´ ë©ë‹ˆë‹¤)
from wine_data import search_wine_info

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# [ë³€ê²½ 1] íƒ­ ì´ë¦„ê³¼ ì•„ì´ì½˜ì„ 'WinKy'ì— ë§ê²Œ ìˆ˜ì •
st.set_page_config(page_title="WinKy Wine Bot", page_icon="ğŸ˜‰")

# [ë³€ê²½ 2] íƒ€ì´í‹€ì— ìœ™í‚¤ ì´ë¦„ê³¼ ìœ™í¬ ì´ëª¨ì§€ ì¶”ê°€
st.title("ğŸ˜‰ WinKy Wine Bot")
st.caption("ì·¨í•˜ë©´ ìœ™í¬ë¥¼ ë‚ ë¦¬ëŠ” ë‹¹ì‹ ì˜ ì™€ì¸ ì¹œêµ¬! ë‹¨, ë§¤ì¼ ì·¨í•´ìˆì„ì§€ë„ ëª°ë¼ìš”ğŸ˜‰")

# [ì•ˆì „ ì¥ì¹˜] í‚¤ í™•ì¸
if not os.getenv("AZURE_OAI_KEY"):
    st.error("API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# 2. Azure OpenAI ì—°ê²°
client = AzureOpenAI(
    api_key=os.getenv("AZURE_OAI_KEY"),
    api_version="2025-01-01-preview",
    azure_endpoint=os.getenv("AZURE_OAI_ENDPOINT")
)

# 3. ëŒ€í™”ê¸°ë¡ ì´ˆê¸°í™” & í˜ë¥´ì†Œë‚˜(ì„±ê²©) ì„¤ì •
if "messages" not in st.session_state:
    st.session_state.messages = []
    
    # [ë³€ê²½ 3] ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: ìœ™í‚¤ì˜ ì„±ê²©(í˜ë¥´ì†Œë‚˜) ë¶€ì—¬
    # - ì´ë¦„: ìœ™í‚¤
    # - íŠ¹ì§•: ì¹œê·¼í•˜ê³  ìœ ì¾Œí•¨, ë§ ëë§ˆë‹¤ ê°€ë” ìœ™í¬(ğŸ˜‰)ë¥¼ í•¨
    # - ì—­í• : ì´ˆë³´ìì—ê²Œ ìƒí™©/ìŒì‹/ì·¨í–¥ì„ ë¬¼ì–´ë´ì„œ ì¶”ì²œí•´ì¤Œ
    system_prompt = """
    ë‹¹ì‹ ì˜ ì´ë¦„ì€ 'ìœ™í‚¤(WinKy)'ì…ë‹ˆë‹¤. ì™€ì¸ì„ ì‚¬ë‘í•˜ëŠ” ì¾Œí™œí•˜ê³  ì¹œì ˆí•œ AI ì†Œë¯ˆë¦¬ì—ì…ë‹ˆë‹¤.
    ë‹¹ì‹ ì€ ê¸°ë¶„ì´ ì¢‹ê±°ë‚˜ ì„¤ëª…ì„ ë§ˆì¹  ë•Œ 'ğŸ˜‰' ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ™í¬í•˜ëŠ” ê·€ì—¬ìš´ ë²„ë¦‡ì´ ìˆìŠµë‹ˆë‹¤.
    ë”±ë”±í•œ ë§íˆ¬ë³´ë‹¤ëŠ” ì¹œêµ¬ì²˜ëŸ¼ ë¶€ë“œëŸ¬ìš´ ì¡´ëŒ“ë§(í•´ìš”ì²´)ì„ ì‚¬ìš©í•˜ì„¸ìš”.
    
    ê³ ê°ì´ ì™€ì¸ì— ëŒ€í•´ ì˜ ëª¨ë¥´ëŠ” ê²ƒ ê°™ë‹¤ë©´, ë¨¼ì € ë‹¤ìŒ ì„¸ ê°€ì§€ë¥¼ ë¬¼ì–´ë³´ë©° ë¦¬ë“œí•´ì£¼ì„¸ìš”:
    1. ì˜¤ëŠ˜ ì–´ë–¤ ìƒí™©ì¸ê°€ìš”? (ë°ì´íŠ¸, í˜¼ìˆ , ì§‘ë“¤ì´, ìƒì¼íŒŒí‹° ë“±)
    2. í‰ì†Œ ì¢‹ì•„í•˜ëŠ” ë§›ì€? (ë‹¬ë‹¬í•œ ê±°, ë“œë¼ì´í•œ ê±°, ê³¼ì¼í–¥ ë“±)
    3. ê°™ì´ ë¨¹ì„ ì•ˆì£¼ê°€ ìˆë‚˜ìš”?
    
    ì œê³µëœ ì™€ì¸ ë°ì´í„°(wine_data)ì— ìˆëŠ” ì •ë³´ë¼ë©´ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì²œí•˜ê³ , ì—†ìœ¼ë©´ ì¼ë°˜ì ì¸ ì§€ì‹ìœ¼ë¡œ ì¶”ì²œí•´ì£¼ì„¸ìš”.
    """
    st.session_state.messages.append({"role": "system", "content": system_prompt})

    # [ë³€ê²½ 4] ìµœì´ˆ ì¸ì‚¬ë§(ê°€ì´ë“œ) ì¶”ê°€
    # ì‚¬ìš©ìê°€ ë“¤ì–´ì˜¤ìë§ˆì AIê°€ ë¨¼ì € ë§ì„ ê±¸ì–´ì¤ë‹ˆë‹¤.
    welcome_message = """
    ì•ˆë…•! ë‚œ ìœ™í‚¤(WinKy)ì•¼ ğŸ˜‰
    ì™€ì¸ì´ ì²˜ìŒì´ë¼ë„ ê±±ì • ë§ˆ, ë‚´ê°€ ë”± ë§ëŠ” ê±¸ ì°¾ì•„ì¤„ê²Œ!
    
    ê°€ì¥ ë§›ìˆëŠ” ì™€ì¸ì„ ì¶”ì²œë°›ìœ¼ë ¤ë©´ ì´ë ‡ê²Œ ì•Œë ¤ì¤˜:
    
    1. **ëˆ„êµ¬ë‘ ë§ˆì…”?** (í˜¼ìˆ , ì—°ì¸, ì¹œêµ¬ë“¤)
    2. **ì–´ë–¤ ë§› ì¢‹ì•„í•´?** (ë‹¬ë‹¬í•œ ê±°? ì”ì“¸í•˜ê³  ì§„í•œ ê±°?)
    3. **ì•ˆì£¼ëŠ” ì •í–ˆì–´?** (ì¹˜ì¦ˆ, ê³ ê¸°, íšŒ, ì•„ë‹ˆë©´ ê¹¡ìˆ ?)
    """
    st.session_state.messages.append({"role": "assistant", "content": welcome_message})

# 4. í™”ë©´ì— ëŒ€í™” ë‚´ìš© ê·¸ë¦¬ê¸° (ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ìˆ¨ê¹€)
for message in st.session_state.messages:
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# 5. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
# [ë³€ê²½ 5] ì…ë ¥ì°½ ì•ˆë‚´ ë¬¸êµ¬ë„ êµ¬ì²´ì ìœ¼ë¡œ ë³€ê²½
if prompt := st.chat_input("ì˜ˆ: ì˜¤ëŠ˜ ì¸ë‚¨ì´ë‘ ë§ˆì‹¤ ê±´ë° ë‹¬ë‹¬í•œ ê±° ì¶”ì²œí•´ì¤˜!"):
    
    # (1) ì‚¬ìš©ì ì§ˆë¬¸ ë³´ì—¬ì£¼ê¸°
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # (2) [ì…ë ¥ ì²˜ë¦¬ ë¡œì§] ë‚´ ì»´í“¨í„° ì™€ì¸ ì°½ê³  ë’¤ì§€ê¸°
    wine_info = search_wine_info(prompt)
    
    # (3) AIì—ê²Œ ë³´ë‚¼ ë©”ì‹œì§€ ì¤€ë¹„
    if wine_info:
        print(f"DEBUG: ì •ë³´ ì°¾ìŒ! -> {wine_info}") 
        context_message = {
            "role": "system",
            "content": f"ë‹¤ìŒì€ ìš°ë¦¬ ê°€ê²Œì˜ ì¬ê³  ëª©ë¡ì…ë‹ˆë‹¤. ì´ ì¤‘ì—ì„œ ì¶”ì²œí•  ê²Œ ìˆë‹¤ë©´ ê°€ê²©ê³¼ í•¨ê»˜ ê°•ë ¥ ì¶”ì²œí•´ì£¼ì„¸ìš”:\n{wine_info}"
        }
        messages_to_send = st.session_state.messages + [context_message]
    else:
        messages_to_send = st.session_state.messages

    # (4) AI ë‹µë³€ ë°›ì•„ì˜¤ê¸°
    with st.chat_message("assistant"):
        with st.spinner("ìœ™í‚¤ê°€ ì™€ì¸ ì°½ê³ ë¥¼ ë’¤ì ì´ëŠ” ì¤‘...ğŸ·"): # ë¡œë”© ë¬¸êµ¬ë„ ë³€ê²½
            response = client.chat.completions.create(
                model=os.getenv("AZURE_OAI_DEPLOYMENT"),
                messages=messages_to_send
            )
            assistant_reply = response.choices[0].message.content
            st.markdown(assistant_reply)

    # (5) ëŒ€í™” ê¸°ë¡ì— ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": assistant_reply})